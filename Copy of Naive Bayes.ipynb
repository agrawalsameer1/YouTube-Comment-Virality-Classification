{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import csv\n","\n","def read_processed_csv(csv_path):\n","    texts = []\n","    labels = []\n","\n","    with open(csv_path, 'r', encoding='utf-8') as f:\n","        reader = csv.DictReader(f)\n","\n","        for row in reader:\n","            try:\n","                comment = row[\"comment\"].strip()\n","                label = int(row[\"viral\"])\n","\n","                # Basic validation\n","                if not comment:  # Skip empty comments\n","                    continue\n","\n","                if label not in (0, 1):  # Ensure binary label\n","                    continue\n","\n","                texts.append(comment)\n","                labels.append(label)\n","\n","            except (ValueError, KeyError) as e:\n","                # Skip rows with missing or invalid data\n","                continue\n","\n","    return texts, labels"],"metadata":{"id":"oBim61VlEHLu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","texts, labels = read_processed_csv('dataset_processed.csv')\n","\n","pos_texts = []\n","pos_labels = []\n","neg_texts = []\n","neg_labels = []\n","\n","for t, l in zip(texts, labels):\n","    if l == 1:\n","        pos_texts.append(t)\n","        pos_labels.append(1)\n","    elif l == 0:\n","        neg_texts.append(t)\n","        neg_labels.append(0)\n","\n","ct = len(pos_labels)\n","\n","k = min(len(neg_texts), ct * 5)\n","neg_indices = random.sample(range(len(neg_texts)), k)\n","\n","neg_texts_sampled = [neg_texts[i] for i in neg_indices]\n","neg_labels_sampled = [neg_labels[i] for i in neg_indices]\n","\n","# Final balanced dataset\n","texts_balanced = pos_texts + neg_texts_sampled\n","labels_balanced = pos_labels + neg_labels_sampled\n","\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(texts_balanced)\n","y = np.array(labels_balanced, dtype=int)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.3,\n","    random_state=42,\n","    stratify=y\n",")\n","\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","\n","y_train_pred = model.predict(X_train)\n","y_test_pred = model.predict(X_test)\n","\n","print(\"Training accuracy:\", accuracy_score(y_train, y_train_pred))\n","print(\"Test accuracy:\", accuracy_score(y_test, y_test_pred))\n","\n","print(\"Train classification report:\")\n","print(classification_report(y_train, y_train_pred, digits=3))\n","\n","print(\"Test classification report:\")\n","print(classification_report(y_test, y_test_pred, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9_vIBkADeSj","executionInfo":{"status":"ok","timestamp":1764985164633,"user_tz":480,"elapsed":2774,"user":{"displayName":"Sameer Agrawal","userId":"18062353540738892167"}},"outputId":"c598ce74-3e2c-4a5f-ca63-2442fd5c9374"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading: dataset_processed.csv\n","✓ Loaded 129428 comments (21572 viral, 107856 non-viral)\n","Training accuracy: 0.8862459850550227\n","Test accuracy: 0.8535115506451364\n","\n","--- Train classification report ---\n","              precision    recall  f1-score   support\n","\n","           0      0.919     0.947     0.933     75499\n","           1      0.688     0.581     0.630     15100\n","\n","    accuracy                          0.886     90599\n","   macro avg      0.803     0.764     0.781     90599\n","weighted avg      0.880     0.886     0.882     90599\n","\n","\n","--- Test classification report ---\n","              precision    recall  f1-score   support\n","\n","           0      0.905     0.921     0.913     32357\n","           1      0.566     0.518     0.541      6472\n","\n","    accuracy                          0.854     38829\n","   macro avg      0.736     0.719     0.727     38829\n","weighted avg      0.849     0.854     0.851     38829\n","\n"]}]},{"cell_type":"code","source":["def top_discriminative_words(model, vectorizer, k=20):\n","    feature_names = np.array(vectorizer.get_feature_names_out())\n","\n","    # log P(word|class1) - log P(word|class0)\n","    log_odds = model.feature_log_prob_[1] - model.feature_log_prob_[0]\n","\n","    # Most positive → strong for class 1\n","    idx_pos = np.argsort(log_odds)[::-1][:k]\n","    # Most negative → strong for class 0\n","    idx_neg = np.argsort(log_odds)[:k]\n","\n","    top_class1 = list(zip(feature_names[idx_pos], log_odds[idx_pos]))\n","    top_class0 = list(zip(feature_names[idx_neg], log_odds[idx_neg]))\n","\n","    return top_class0, top_class1\n","\n","top0, top1 = top_discriminative_words(model, vectorizer, k=20)\n","\n","print(\"Top words for class 0:\")\n","for w, score in top0:\n","    print(f\"{w:25s} {score: .3f}\")\n","\n","print(\"\\nTop words for class 1:\")\n","for w, score in top1:\n","    print(f\"{w:25s} {score: .3f}\")"],"metadata":{"id":"26HeZfbvS-yA","executionInfo":{"status":"ok","timestamp":1764985174545,"user_tz":480,"elapsed":7,"user":{"displayName":"Sameer Agrawal","userId":"18062353540738892167"}},"outputId":"66eccbdc-d000-4a0f-846c-90870b57ecb3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top words for class 0 (negative / non-toxic):\n","raid                      -6.976\n","que                       -4.414\n","yusufte                   -3.654\n","felipe                    -3.588\n","русский                   -3.530\n","neto                      -3.505\n","eu                        -3.415\n","не                        -3.285\n","faze                      -3.254\n","br                        -3.238\n","birthday                  -3.188\n","se                        -3.188\n","en                        -3.188\n","español                   -3.154\n","te                        -3.043\n","mods                      -3.003\n","modded                    -3.003\n","sou                       -2.982\n","русские                   -2.939\n","indonesia                 -2.917\n","\n","Top words for class 1 (positive / toxic):\n","awakens                    6.473\n","triology                   5.913\n","remastered                 4.153\n","router                     3.934\n","screeches                  3.597\n","vocabulary                 3.241\n","sunset                     3.241\n","acrobat                    3.192\n","flnale                     3.087\n","plead                      2.969\n","swirling                   2.969\n","ourselves                  2.969\n","heath                      2.835\n","lilypads                   2.835\n","intermission               2.835\n","yeeeeeeeesssssssssss       2.835\n","mercilessly                2.835\n","spoken                     2.835\n","conditions                 2.835\n","gettim                     2.835\n"]}]}]}